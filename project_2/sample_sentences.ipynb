{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "import torch\n",
    "from load_data import LoadData\n",
    "from RNNLM import RNNLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS\n",
      "\n",
      "BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS\n",
      "\n",
      "BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS\n",
      "\n",
      "BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS\n",
      "\n",
      "BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS BOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set variables\n",
    "T = 1.0\n",
    "sample_length = 20\n",
    "amount_of_samples = 5\n",
    "sampling_method = \"greedy\" #\"temparature\"\n",
    "\n",
    "# Initialize the device which to run the model on\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = LoadData(\"TRAIN_DATA\")\n",
    "vocab_len = dataset.vocab_len\n",
    "\n",
    "# Initialize the model that we are going to use\n",
    "model = torch.load(\"LSTM.pt\", map_location='cpu')\n",
    "\n",
    "# Generate some sentences by sampling from the model\n",
    "for i in range(amount_of_samples):\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize variables\n",
    "    sentence = []\n",
    "    h = None\n",
    "    c = torch.tensor([[dataset.get_id(\"BOS\")]]).to(device)\n",
    "    \n",
    "    for i in range(sample_length-1):\n",
    "        sentence.append(c.squeeze())\n",
    "        out, h = model.predict(c, h)\n",
    "        if sampling_method is \"greedy\":\n",
    "            c = torch.tensor([[out.argmax()]])\n",
    "        else: \n",
    "            c = softmax(1/T * out.squeeze()).multinomial(1)\n",
    "            c = one_hot_sample(ind, dataset.vocab_size).to(device)\n",
    "\n",
    "    sentence.append(c.squeeze())\n",
    "    sentence = torch.tensor(sentence)\n",
    "    s = dataset.convert_to_string(sentence.tolist())\n",
    "    print(s+ \"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
